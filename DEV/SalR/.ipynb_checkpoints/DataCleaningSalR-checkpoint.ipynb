{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "from alpha_api import api_key\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "ts = TimeSeries(key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List with the tickers of the chosen stocks\n",
    "global_stocks = [\"DAL\", \"AMZN\", \"EXPE\", \"UBER\", \"WMT\"] \n",
    "comm_stocks = [\"PEG\", \"TIF\", \"AG\", \"BP\", \"NEM\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to call the API and get stocks in a list of tickers\n",
    "def getStockdf (stocks):\n",
    "    \n",
    "    # Create dictionary to store stocks with their data\n",
    "    sal_stocks_dictionary_list = {}\n",
    "\n",
    "    # iterate through list and call the ts.get_daily() for each stock inside the stocks list and store list in the dictionary  \n",
    "    for stock in stocks:\n",
    "        data, meta_data = ts.get_daily(stock, outputsize=\"full\")\n",
    "        sal_stocks_dictionary_list[stock] = data\n",
    "\n",
    "    # intialize list \n",
    "    sal_stock_list = []\n",
    "\n",
    "    \"\"\"We have to store info in a way that retains the name, date, and stock information in a format that can be fed into the pandas dataframe without losing it's order, so we do the below\"\"\"\n",
    "    # iterate through each stocks dictionary\n",
    "    for stock, value in sal_stocks_dictionary_list.items():\n",
    "        # Inside the stocks value is a dictionary with date as the key and the open-volume numbers as the dictionary, so iterate through the value dictionary\n",
    "        for date, info in value.items():\n",
    "            # store the date, stock, and info within the dictionary into a tuple and append to the stock_list\n",
    "            sal_stock_list.append((date, stock, info['1. open'], info['2. high'], info['3. low'], info['4. close'], info['5. volume']))\n",
    "\n",
    "    # Store each column into a list\n",
    "    dates = [date[0] for date in sal_stock_list]\n",
    "    stock = [stock[1] for stock in sal_stock_list]\n",
    "    open_s = [open_s[2] for open_s in sal_stock_list]\n",
    "    high_s = [high_s[3] for high_s in sal_stock_list]\n",
    "    low_s = [low_s[4] for low_s in sal_stock_list]\n",
    "    close_s = [close_s[5] for close_s in sal_stock_list]\n",
    "    volume_s = [volume_s[6] for volume_s in sal_stock_list]\n",
    "\n",
    "    # Create a dictionary with each key have its value as a list of their respective data\n",
    "    sal_final_dictionary = {'dates': dates, 'stock': stock, 'open': open_s, 'close': close_s, 'high': high_s, 'low': low_s, 'close': close_s, 'volume': volume_s}\n",
    "\n",
    "    # store into dateframe\n",
    "    sal_raw_df = pd.DataFrame(data=final_dictionary)\n",
    "    return raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Entertainment stocks\n",
    "raw_global_df = getStockdf(ent_stocks)\n",
    "\n",
    "raw_dal_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"DAL\"]\n",
    "raw_amzn_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"AMZN\"]\n",
    "raw_expe_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"EXPE\"]\n",
    "raw_uber_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"UBER\"]\n",
    "raw_wmt_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"WMT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Food stocks\n",
    "raw_comm_df = getStockdf(food_stocks)\n",
    "\n",
    "raw_peg_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"PEG\"]\n",
    "raw_tif_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"TIF\"]\n",
    "raw_ag_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"AG\"]\n",
    "raw_nem_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"NEM\"]\n",
    "raw_bp_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"BP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_df_list = [raw_dal_df, raw_amzn_df, raw_expe_df, raw_uber_df, raw_wmt_df, raw_peg_df, raw_tif_df, raw_ag_df, raw_nem_df, raw_bp_df]\n",
    "\n",
    "for x in range (len(sal_df_list)):\n",
    "    sal_df_list[x] = sal_df_list[x].iloc[0:254]\n",
    "    \n",
    "sal_onethird_df = pd.concat(sal_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'onethird_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store sal_onethird_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
