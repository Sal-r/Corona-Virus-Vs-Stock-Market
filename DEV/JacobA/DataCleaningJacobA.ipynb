{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'alpha_api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-70e2e31dc008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malpha_vantage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malpha_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'alpha_api'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "from alpha_api import api_key\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "ts = TimeSeries(key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List with the tickers of the chosen stocks\n",
    "ent_stocks = [\"NFLX\", \"ATVI\", \"DIS\", \"AMC\", \"HAS\"] \n",
    "food_stocks = [\"KO\", \"BUD\", \"PEP\", \"GIS\", \"MCD\"]\n",
    "ess_stocks = [\"CLX\", \"PG\", \"CL\", \"CVS\", \"JNJ\"]\n",
    "\n",
    "cars_stocks = ['TSLA', 'F', 'TM', 'FUJHY', 'FCAU']\n",
    "tech_stocks = ['CSCO', 'MSFT', 'AAPL', 'GOOGL', 'SNE']\n",
    "index_stocks = ['DJI', 'NDAQ', 'INX']\n",
    "\n",
    "global_stocks = [\"DAL\", \"AMZN\", \"EXPE\", \"UBER\", \"WMT\"] \n",
    "comm_stocks = [\"PEG\", \"TIF\", \"AG\", \"BP\", \"NEM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to call the API and get stocks in a list of tickers\n",
    "def getStockdf (stocks):\n",
    "    \n",
    "    # Create dictionary to store stocks with their data\n",
    "    stocks_dictionary_list = {}\n",
    "\n",
    "    # iterate through list and call the ts.get_daily() for each stock inside the stocks list and store list in the dictionary  \n",
    "    for stock in stocks:\n",
    "        data, meta_data = ts.get_daily(stock, outputsize=\"full\")\n",
    "        stocks_dictionary_list[stock] = data\n",
    "\n",
    "    # intialize list \n",
    "    stock_list = []\n",
    "\n",
    "    \"\"\"We have to store info in a way that retains the name, date, and stock information in a format that can be fed into the pandas dataframe without losing it's order, so we do the below\"\"\"\n",
    "    # iterate through each stocks dictionary\n",
    "    for stock, value in stocks_dictionary_list.items():\n",
    "        # Inside the stocks value is a dictionary with date as the key and the open-volume numbers as the dictionary, so iterate through the value dictionary\n",
    "        for date, info in value.items():\n",
    "            # store the date, stock, and info within the dictionary into a tuple and append to the stock_list\n",
    "            stock_list.append((date, stock, info['1. open'], info['2. high'], info['3. low'], info['4. close'], info['5. volume']))\n",
    "\n",
    "    # Store each column into a list\n",
    "    dates = [date[0] for date in stock_list]\n",
    "    stock = [stock[1] for stock in stock_list]\n",
    "    open_s = [open_s[2] for open_s in stock_list]\n",
    "    high_s = [high_s[3] for high_s in stock_list]\n",
    "    low_s = [low_s[4] for low_s in stock_list]\n",
    "    close_s = [close_s[5] for close_s in stock_list]\n",
    "    volume_s = [volume_s[6] for volume_s in stock_list]\n",
    "\n",
    "    # Create a dictionary with each key have its value as a list of their respective data\n",
    "    final_dictionary = {'dates': dates, 'stock': stock, 'open': open_s, 'close': close_s, 'high': high_s, 'low': low_s, 'close': close_s, 'volume': volume_s}\n",
    "\n",
    "    # store into dateframe\n",
    "    raw_df = pd.DataFrame(data=final_dictionary)\n",
    "    return raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Entertainment stocks\n",
    "raw_ent_df = getStockdf(ent_stocks)\n",
    "\n",
    "raw_nflx_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"NFLX\"]\n",
    "raw_atvi_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"ATVI\"]\n",
    "raw_dis_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"DIS\"]\n",
    "raw_amc_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"AMC\"]\n",
    "raw_has_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"HAS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Food stocks\n",
    "raw_food_df = getStockdf(food_stocks)\n",
    "\n",
    "raw_ko_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"KO\"]\n",
    "raw_bud_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"BUD\"]\n",
    "raw_pep_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"PEP\"]\n",
    "raw_gis_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"GIS\"]\n",
    "raw_mcd_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"MCD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Essentials stocks\n",
    "raw_ess_df = getStockdf(ess_stocks)\n",
    "\n",
    "raw_clx_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"CLX\"]\n",
    "raw_pg_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"PG\"]\n",
    "raw_cl_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"CL\"]\n",
    "raw_cvs_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"CVS\"]\n",
    "raw_jnj_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"JNJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Cars stocks\n",
    "raw_cars_df = getStockdf(cars_stocks)\n",
    "\n",
    "raw_tsla_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"TSLA\"]\n",
    "raw_f_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"F\"]\n",
    "raw_tm_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"TM\"]\n",
    "raw_fujhy_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"FUJHY\"]\n",
    "raw_fcau_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"FCAU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Tech stocks\n",
    "raw_tech_df = getStockdf(tech_stocks)\n",
    "\n",
    "raw_csco_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"CSCO\"]\n",
    "raw_msft_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"MSFT\"]\n",
    "raw_aapl_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"AAPL\"]\n",
    "raw_googl_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"GOOGL\"]\n",
    "raw_sne_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"SNE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Index stocks\n",
    "raw_index_df = getStockdf(index_stocks)\n",
    "\n",
    "raw_dji_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"DJI\"]\n",
    "raw_ndaq_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"NDAQ\"]\n",
    "raw_inx_df = raw_ess_df.loc[raw_ess_df[\"stock\"] == \"INX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual Global stocks\n",
    "raw_global_df = getStockdf(global_stocks)\n",
    "\n",
    "raw_dal_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"DAL\"]\n",
    "raw_amzn_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"AMZN\"]\n",
    "raw_expe_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"EXPE\"]\n",
    "raw_uber_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"UBER\"]\n",
    "raw_wmt_df = raw_ent_df.loc[raw_ent_df[\"stock\"] == \"WMT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for individual commodities stocks\n",
    "raw_comm_df = getStockdf(comm_stocks)\n",
    "\n",
    "raw_peg_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"PEG\"]\n",
    "raw_tif_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"TIF\"]\n",
    "raw_ag_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"AG\"]\n",
    "raw_nem_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"NEM\"]\n",
    "raw_bp_df = raw_food_df.loc[raw_food_df[\"stock\"] == \"BP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [raw_nflx_df, raw_atvi_df, raw_dis_df, raw_amc_df, raw_has_df, \n",
    "           raw_ko_df, raw_bud_df, raw_pep_df, raw_gis_df, raw_mcd_df, \n",
    "           raw_clx_df, raw_pg_df, raw_cl_df, raw_cvs_df, raw_jnj_df,\n",
    "           raw_tsla_df, raw_f_df, raw_tm_df, raw_fujhy_df, raw_fcau_df,\n",
    "           raw_csco_df, raw_msft_df, raw_aapl_df, raw_googl_df, raw_sne_df,\n",
    "           raw_dji_df, raw_ndaq_df, raw_inx_df, raw_dal_df, raw_amzn_df,\n",
    "           raw_expe_df, raw_uber_df, raw_wmt_df, raw_peg_df, raw_tif_df,\n",
    "           raw_ag_df, raw_nem_df, raw_bp_df]\n",
    "\n",
    "for x in range (len(df_list)):\n",
    "    df_list[x] = df_list[x].iloc[0:254]\n",
    "    \n",
    "full_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'onethird_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
